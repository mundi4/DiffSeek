import { BLOCK_ELEMENTS, DIFF_TAG_NAME, HANGUL_ORDER, MANUAL_ANCHOR_ELEMENT_NAME, TEXT_FLOW_CONTAINERS } from "../../constants";

import { createTrie, extractStartCharsFromTrie, type TrieNode } from "./trie";
import { normalizedCharMap } from "./normalizedCharMap";
import { quickHash53ToString } from "@/utils/quickHash53ToString";

export const MANUAL_ANCHOR1 = "ğŸ”—@";
export const MANUAL_ANCHOR2 = "ğŸ”—#";

export type RichToken = {
	text: string;
	flags: number;
	range: LightRange | Range;
	lineNum: number;
	container: TextFlowContainer;
};

export const enum TokenFlags {
	None = 0,
	LINE_START = 1 << 0, // 1
	LINE_END = 1 << 1, // 2
	BLOCK_START = 1 << 2, // 4
	BLOCK_END = 1 << 3, // 8
	CONTAINER_START = 1 << 4, // 16
	CONTAINER_END = 1 << 5, // 32
	TABLE_START = 1 << 6, // 64
	TABLE_END = 1 << 7, // 128
	TABLEROW_START = 1 << 8, // 256
	TABLEROW_END = 1 << 9, // 512
	TABLECELL_START = 1 << 10, // 1024
	TABLECELL_END = 1 << 11, // 2048
	NO_JOIN_PREV = 1 << 12, // 4096 @@@, ### ë“±ë“±
	NO_JOIN_NEXT = 1 << 13, // 8192 @@@, ### ë“±ë“±
	WILD_CARD = 1 << 14, // 16384
	MANUAL_ANCHOR = 1 << 15, // 32768  @@@, ### ë“±ë“±
	IMAGE = 1 << 16, // 65536
	HTML_SUP = 1 << 17, // 131072
	HTML_SUB = 1 << 18, // 262144
	SECTION_HEADING_TYPE1 = 1 << 19, // 1.
	SECTION_HEADING_TYPE2 = 1 << 20, // ê°€.
	SECTION_HEADING_TYPE3 = 1 << 21, // (1)
	SECTION_HEADING_TYPE4 = 1 << 22, // (ê°€)
	SECTION_HEADING_TYPE5 = 1 << 23, // 1)
	SECTION_HEADING_TYPE6 = 1 << 24, // ê°€)

	SECTION_HEADING_MASK = SECTION_HEADING_TYPE1 |
		SECTION_HEADING_TYPE2 |
		SECTION_HEADING_TYPE3 |
		SECTION_HEADING_TYPE4 |
		SECTION_HEADING_TYPE5 |
		SECTION_HEADING_TYPE6,
}

// const normalizeChars: { [ch: string]: string } = {};

const spaceChars: Record<string, boolean> = {
	" ": true,
	"\t": true,
	"\n": true,
	"\u00A0": true, // &nbsp; ??
	"\r": true, // ê¸€ì„...
	"\f": true, // ì´ê²ƒë“¤ì€...
	"\v": true, // ë³¼ì¼ì´ ì—†ì„ê²ƒ...
};

// type CharMetadata = {
// 	isSpace: boolean;
// 	isSplit: boolean;
// 	normalizedChar: number;
// 	trieNode: TrieNode | null;
// }

// wildcards.
// ì´ê±¸ ì–´ë–»ê²Œ êµ¬í˜„í•´ì•¼í• ì§€ ê°ì´ ì•ˆì˜¤ì§€ë§Œ ì§€ê¸ˆìœ¼ë¡œì¨ëŠ” ì–˜ë„¤ë“¤ì„ atomicí•˜ê²Œ ì·¨ê¸‰(ì‚¬ì´ì— ê³µë°±ì´ ìˆì–´ë„ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ë§Œë“¬. '(í˜„í–‰ê³¼ ê°™ìŒ)'ì—ì„œ ì¼ë¶€ë¶„ë§Œ ë§¤ì¹˜ë˜ëŠ” ê²ƒì„ ë°©ì§€)
// ê¸€ìë‹¨ìœ„ë¡œ í† í°í™”í•˜ëŠ” ê²½ìš°ì—ë„ ì–˜ë„¤ë“¤ì€ (...) í†µì±„ë¡œ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ì·¨ê¸‰.
// ì™€ì¼ë“œì¹´ë“œdiffì¸ ê²½ìš° ë‹¤ë¥¸ diffì™€ ë³‘í•©ë˜ì§€ ì•Šìœ¼ë©´ ì¢‹ì§€ë§Œ ì™€ì¼ë“œì¹´ë“œê°€ ì–¼ë§ˆë‚˜ greedyí•˜ê²Œ ë°˜ëŒ€ìª½ í…ìŠ¤íŠ¸ë¥¼ ì¡ì•„ë¨¹ì–´ì•¼ í• ì§€
// ì–‘ìª½ì— wildcardê°€ ë™ì‹œì— ë‚˜ì˜¤ëŠ” ê²½ìš° ê²½ê³„ë¥¼ ì–´ë””ì„œ ì–´ë–»ê²Œ ì§¤ë¼ì•¼í• ì§€ ì‰½ì§€ ì•ŠìŒ.
// ë˜í•œ wildcardë¥¼ ê°•ì œë¡œ ë‹¤ë¥¸ diffì™€ ë¶„ë¦¬í•˜ëŠ” ê²½ìš° diffê°€ ê°™ì€ ìœ„ì¹˜ì— ë‘ ê°œ ì´ìƒ ìƒê¸°ê²Œ ë˜ëŠ” ìˆ˜ê°€ ìˆë‹¤. (wildcardì™€ wildcardê°€ ì•„ë‹Œ ê²ƒ)
// ì´ ê²½ìš° ì •í™•íˆ ê°™ì€ ìœ„ì¹˜ì— ë‘ê°œì˜ diffë¥¼ ë Œë”ë§í•´ì•¼í•˜ê³  ê²°êµ­ ë‘ê°œê°€ ê²¹ì³ë³´ì´ê²Œ ë˜ëŠ”ë° ë¶„ê°„ì´ ì˜ ì•ˆëœë‹¤.
const wildcardTrie = createTrie(true);
wildcardTrie.insert("(ì¶”ê°€)", TokenFlags.WILD_CARD);
wildcardTrie.insert("(ì‚­ì œ)", TokenFlags.WILD_CARD);
wildcardTrie.insert("(ì‹ ì„¤)", TokenFlags.WILD_CARD);
wildcardTrie.insert("(ìƒëµ)", TokenFlags.WILD_CARD);
wildcardTrie.insert("(í˜„í–‰ê³¼ê°™ìŒ)", TokenFlags.WILD_CARD);

const wildcardTrieNode = wildcardTrie.root.next("(")!;

const sectionHeadingTrie = createTrie(false);
for (let i = 1; i < 40; i++) {
	sectionHeadingTrie.insert(`${i}.`, TokenFlags.SECTION_HEADING_TYPE1);
	sectionHeadingTrie.insert(`(${i})`, TokenFlags.SECTION_HEADING_TYPE3);
	sectionHeadingTrie.insert(`${i})`, TokenFlags.SECTION_HEADING_TYPE5);
}

for (let i = 0; i < HANGUL_ORDER.length; i++) {
	sectionHeadingTrie.insert(`${HANGUL_ORDER[i]}.`, TokenFlags.SECTION_HEADING_TYPE2);
	sectionHeadingTrie.insert(`(${HANGUL_ORDER[i]})`, TokenFlags.SECTION_HEADING_TYPE4);
	sectionHeadingTrie.insert(`${HANGUL_ORDER[i]})`, TokenFlags.SECTION_HEADING_TYPE6);
}
const SectionHeadingTrieNode = sectionHeadingTrie.root;
const sectionHeadingStartChars = extractStartCharsFromTrie(SectionHeadingTrieNode);

function normalize(text: string): string {
	let result = "";
	for (const char of text) {
		const charCode = char.codePointAt(0)!;
		const normCharCode = normalizedCharMap[charCode];
		if (normCharCode !== undefined) {
			result += String.fromCodePoint(normCharCode);
		} else {
			result += char;
		}
	}
	return result;
}

export class TokenizeContext {
	#rootContent: HTMLElement;
	#onDone: (tokens: RichToken[]) => void;
	#cancelled: boolean;
	#generator: Generator<void, { tokens: RichToken[]; containers: Map<HTMLElement, TextFlowContainer> }, IdleDeadline> | null = null;
	#callbackId: number | null = null;

	constructor(rootContent: HTMLElement, onDone: (tokens: RichToken[]) => void) {
		this.#rootContent = rootContent;
		this.#onDone = onDone;
		this.#cancelled = false;
	}

	start() {
		if (this.#cancelled) {
			throw new Error("Cannot start a cancelled context");
		}

		if (this.#callbackId !== null) {
			throw new Error("Cannot reuse context");
		}

		this.#queueNextStep();
	}

	cancel() {
		this.#cancelled = true;
		if (this.#callbackId !== null) {
			cancelIdleCallback(this.#callbackId);
			this.#callbackId = null;
		}
	}

	#step(idleDeadline: IdleDeadline): void {
		if (this.#cancelled) {
			return;
		}

		if (this.#generator === null) {
			// idleDeadlineê³¼ í•¨ê»˜ generatorë¥¼ ìƒì„±ì„ í•˜ë ¤ë©´ ì—¬ê¸°ì—ì„œ ìƒì„±í•´ì•¼ í•¨.
			this.#generator = this.#generate(idleDeadline);
		}

		const { done, value } = this.#generator.next(idleDeadline);
		if (this.#cancelled) {
			return;
		}

		if (done) {
			this.#onDone(value.tokens);
		} else {
			this.#queueNextStep();
		}
	}

	#queueNextStep() {
		this.#callbackId = requestIdleCallback((IdleDeadline) => this.#step(IdleDeadline), { timeout: 500 });
	}

	*#generate(idleDeadline: IdleDeadline): Generator<void, { tokens: RichToken[]; containers: Map<HTMLElement, TextFlowContainer> }, IdleDeadline> {
		type _BlockInfo = {
			element: HTMLElement;
			container: TextFlowContainer;
			startTokenIndex: number; // ì‹œì‘ í† í° ì¸ë±ìŠ¤
			tokenCount: number; // í† í° ê°œìˆ˜
			depth: number;
		};

		const tokens: RichToken[] = [];
		const containers: Map<HTMLElement, TextFlowContainer> = new Map();
		const root = this.#rootContent;
		const textNodeBuf: Text[] = [];
		const textNodeBufIndices: number[] = [];
		let tokenIndex = 0;
		let currentToken: RichToken | null = null;
		let nextTokenFlags = 0;
		let recursionCount = 0;
		let lineNum = 1;
		let shouldNormalize = false;

		const blockStack: _BlockInfo[] = [];
		let currentBlock: _BlockInfo | null = null;

		const containerStack: TextFlowContainer[] = [];
		let currentContainer: TextFlowContainer = {
			element: root as HTMLElement,
			parent: null,
			depth: 0,
			startTokenIndex: 0,
			tokenCount: 0,
		};

		function processToken(textNode: Text, startOffset: number, endOffset: number, flags: number = 0) {
			let text = textNode.nodeValue!.slice(startOffset, endOffset);
			if (shouldNormalize) {
				text = normalize(text);
				shouldNormalize = false;
			}
			if (currentToken) {
				currentToken.text += text;
				(currentToken.range as LightRange).endContainer = textNode;
				(currentToken.range as LightRange).endOffset = endOffset;
			} else {
				currentToken = {
					text: text,
					flags: nextTokenFlags | flags,
					range: {
						startContainer: textNode,
						startOffset: startOffset,
						endContainer: textNode,
						endOffset: endOffset,
					},
					container: currentContainer,
					lineNum: lineNum,
				};
				nextTokenFlags = 0;
			}
		}

		function finalizeToken(flags: number = 0) {
			if (currentToken) {
				currentToken.flags |= flags;
				tokens[tokenIndex] = currentToken;
				if (tokenIndex > 0 && currentToken.flags & TokenFlags.LINE_END) {
					tokens[tokenIndex - 1].flags |= TokenFlags.LINE_END;
				}
				tokenIndex++;
				currentToken = null;
			}
		}

		function findInTrie(trie: TrieNode, bufferIndex: number, charIndex: number) {
			let node: TrieNode | null = trie;
			let i = bufferIndex;
			let j = charIndex;
			do {
				const text = textNodeBuf[i].nodeValue!;
				for (; j < text.length; j++) {
					let ch = text[j];
					// ch = normalizedCharMap[ch] || ch;
					node = node!.next(ch);
					if (!node) {
						return null;
					}
					if (node.word) {
						return { bufferIndex: i, charIndex: j + 1, word: node.word, flags: node.flags };
					}
				}

				i++;
				j = 0;
			} while (i < textNodeBuf.length);
			return null;
		}

		function doTokenizeText() {
			console.assert(textNodeBuf.length > 0, "textNodes should not be empty at this point");
			let nodeIndex = 0;
			let charIndex = 0;

			OUTER: do {
				const textNode = textNodeBuf[nodeIndex];
				const text = textNode.nodeValue!;
				const textLen = text.length;

				let currentStart = -1;

				while (charIndex < textLen) {
					// 4byte ë¬¸ìë¥¼ ìƒê°í•´ì•¼í•œë‹¤. later....
					const cp = text.codePointAt(charIndex)!;
					if (normalizedCharMap[cp] !== undefined) {
						shouldNormalize = true;
					}
					// todo ë¬¸ìê°€ ì•„ë‹ˆë¼ ì½”ë“œí¬ì¸íŠ¸ë¡œ spaceCharë‚˜ normalizeChar ë“±ë“± í™•ì¸í•˜ê¸°

					let char = text[charIndex];

					if (spaceChars[char]) {
						// split here
						if (currentStart !== -1) {
							processToken(textNode, currentStart, charIndex);
							currentStart = -1;
						}
						finalizeToken();
					} else {
						if (char === "(") {
							const match = findInTrie(wildcardTrieNode, nodeIndex, charIndex + 1);
							if (match) {
								const startContainer = textNode;
								const startOffset = charIndex;
								if (currentStart !== -1) {
									processToken(textNode, currentStart, charIndex);
									currentStart = -1;
								}
								finalizeToken();
								currentToken = {
									text: match.word,
									flags: nextTokenFlags | match.flags,
									range: {
										startContainer,
										startOffset,
										endContainer: textNodeBuf[match.bufferIndex],
										endOffset: match.charIndex,
									},
									container: currentContainer,
									lineNum: lineNum,
								};
								nextTokenFlags = 0;
								finalizeToken();
								nodeIndex = match.bufferIndex;
								charIndex = match.charIndex;
								continue OUTER;
							}
						}
						if (sectionHeadingStartChars[char] && nextTokenFlags & TokenFlags.LINE_START && !currentToken && currentStart === -1) {
							const match = findInTrie(SectionHeadingTrieNode, nodeIndex, charIndex);
							if (match) {
								const startContainer = textNode;
								const startOffset = charIndex;
								if (currentStart !== -1) {
									processToken(textNode, currentStart, charIndex);
									currentStart = -1;
								}
								finalizeToken();
								currentToken = {
									text: match.word,
									flags: nextTokenFlags | match.flags,
									range: {
										startContainer,
										startOffset,
										endContainer: textNodeBuf[match.bufferIndex],
										endOffset: match.charIndex,
									},
									container: currentContainer,
									lineNum: lineNum,
								};
								nextTokenFlags = 0;
								finalizeToken();
								nodeIndex = match.bufferIndex;
								charIndex = match.charIndex;
								continue OUTER;
							}
						}

						if (currentStart === -1) {
							currentStart = charIndex;
						}
					}
					// ...
					// ...
					charIndex++;
					if (cp > 0xffff) {
						charIndex++;
					}
				}
				if (currentStart !== -1) {
					processToken(textNode, currentStart, textLen);
					currentStart = -1;
				}
				nodeIndex++;
				charIndex = 0;
			} while (nodeIndex < textNodeBuf.length);

			finalizeToken();

			textNodeBuf.length = 0;
			textNodeBufIndices.length = 0;
		}

		function* traverse(node: Node): Generator<void> {
			const nodeName = node.nodeName;
			const isTextFlowContainer = TEXT_FLOW_CONTAINERS[nodeName] || node === root;
			const isBlockElement = BLOCK_ELEMENTS[nodeName];

			if (isTextFlowContainer) {
				containerStack.push(currentContainer);
				currentContainer = {
					element: node as HTMLElement,
					parent: currentContainer,
					depth: currentContainer.depth + 1,
					startTokenIndex: tokenIndex,
					tokenCount: 0,
				};
				nextTokenFlags |= TokenFlags.CONTAINER_START | TokenFlags.BLOCK_START | TokenFlags.LINE_START;
			}

			if (isBlockElement) {
				if (currentBlock) {
					blockStack.push(currentBlock);
				}
				currentBlock = {
					element: node as HTMLElement,
					container: currentContainer,
					depth: (currentBlock?.depth ?? -1) + 1,
					startTokenIndex: tokenIndex,
					tokenCount: 0,
				};
				nextTokenFlags |= TokenFlags.BLOCK_START | TokenFlags.LINE_START;
			}

			const isTokenBoundary = isTextFlowContainer || isBlockElement || nodeName === "TD";
			if (isTokenBoundary && textNodeBuf.length > 0) {
				doTokenizeText();
			}

			const childNodes = node.childNodes;
			const tokenStartIndex = tokenIndex;

			for (let i = 0; i < childNodes.length; i++) {
				if ((++recursionCount & 31) === 0 && idleDeadline.timeRemaining() < 2) {
					idleDeadline = yield;
				}

				const child = childNodes[i];
				if (child.nodeType === 3) {
					textNodeBuf.push(child as Text);
					textNodeBufIndices.push(i);
				} else if (child.nodeType === 1) {
					const childNodeName = child.nodeName;

					if (childNodeName === DIFF_TAG_NAME) {
						continue;
					}

					if (childNodeName === "IMG") {
						if (textNodeBuf.length > 0) {
							doTokenizeText();
						}

						const range = document.createRange();
						range.selectNode(child);
						currentToken = {
							text: quickHash53ToString((child as HTMLImageElement).src),
							flags: TokenFlags.IMAGE | TokenFlags.NO_JOIN_PREV | TokenFlags.NO_JOIN_NEXT | nextTokenFlags,
							range,
							container: currentContainer,
							lineNum: lineNum,
						};
						nextTokenFlags = 0;
						finalizeToken();
						continue;
					}

					if (childNodeName === MANUAL_ANCHOR_ELEMENT_NAME && (child as HTMLAnchorElement).classList.contains("manual-anchor")) {
						if (textNodeBuf.length > 0) {
							doTokenizeText();
						}
						nextTokenFlags |= TokenFlags.LINE_START;
						lineNum++;

						if (textNodeBuf.length > 0) {
							doTokenizeText();
						}
						const range = document.createRange();
						range.selectNode(child);
						currentToken = {
							text: (child as HTMLAnchorElement).dataset.manualAnchor === "B" ? MANUAL_ANCHOR2 : MANUAL_ANCHOR1,
							flags:
								TokenFlags.MANUAL_ANCHOR |
								TokenFlags.NO_JOIN_PREV |
								TokenFlags.NO_JOIN_NEXT |
								nextTokenFlags |
								TokenFlags.LINE_START |
								TokenFlags.LINE_END,
							range,
							container: currentContainer,
							lineNum: lineNum,
						};
						nextTokenFlags = 0;
						// console.log("manual anchor found", currentToken.text, currentToken.range);
						finalizeToken();
						continue;
					}

					if (childNodeName === "BR" || childNodeName === "HR") {
						if (textNodeBuf.length > 0) {
							doTokenizeText();
						}
						nextTokenFlags |= TokenFlags.LINE_START;
						lineNum++;
						continue;
					}

					yield* traverse(child);
				}
			}

			if (isTokenBoundary && textNodeBuf.length > 0) {
				doTokenizeText();
			}

			const tokenEndIndex = tokenIndex;
			const tokenCount = tokenEndIndex - tokenStartIndex;
			if (tokenCount > 0) {
				const firstToken = tokens[tokenStartIndex];
				const lastToken = tokens[tokenIndex - 1];

				if (nodeName === "SUP" || nodeName === "SUB") {
					// SUP + SUPëŠ” ì¡°ì¸ì´ ê°€ëŠ¥í•´ì•¼ í•˜ë¯€ë¡œ NO_JOIN_PREV, NO_JOIN_NEXT í”Œë˜ê·¸ë¥¼ ì£¼ì§€ ì•ŠìŒ
					// ì˜ˆ: <sup>ì£¼</sup><sup>1)</sup> ì´ëŸ° ê±°ì§€ê°™ì€ ìƒí™©ì´ ë‚˜ì˜¬ ìˆ˜ë„ ìˆë‹¤.
					const commonFlags = nodeName === "SUP" ? TokenFlags.HTML_SUP : TokenFlags.HTML_SUB;
					for (let i = tokenStartIndex; i < tokenIndex; i++) {
						tokens[i].flags |= commonFlags;
					}
				} else if (nodeName === "TD" || nodeName === "TH") {
					if (firstToken) {
						firstToken.flags |=
							TokenFlags.TABLECELL_START | TokenFlags.NO_JOIN_PREV | TokenFlags.CONTAINER_START | TokenFlags.BLOCK_START | TokenFlags.LINE_START;
					}
					if (lastToken) {
						lastToken.flags |=
							TokenFlags.TABLECELL_END | TokenFlags.NO_JOIN_NEXT | TokenFlags.CONTAINER_END | TokenFlags.BLOCK_END | TokenFlags.LINE_END;
					}
					if (tokenCount > 0) {
						lineNum++;
					}
				} else if (nodeName === "TR") {
					if (firstToken) {
						firstToken.flags |= TokenFlags.TABLEROW_START;
					}
					if (lastToken) {
						lastToken.flags |= TokenFlags.TABLEROW_END;
					}
				} else if (nodeName === "TABLE") {
					if (firstToken) {
						firstToken.flags |= TokenFlags.TABLE_START;
					}
					if (lastToken) {
						lastToken.flags |= TokenFlags.TABLE_END;
					}
				}

				if (BLOCK_ELEMENTS[nodeName]) {
					if (firstToken) {
						firstToken.flags |= nextTokenFlags | TokenFlags.BLOCK_START | TokenFlags.LINE_START;
					}
					if (lastToken) {
						lastToken.flags |= TokenFlags.BLOCK_END | TokenFlags.LINE_END;
					}
					nextTokenFlags |= TokenFlags.LINE_START;
					if (tokenCount > 0) {
						lineNum++;
					}
				}

				if (node === root) {
					firstToken.flags |= nextTokenFlags | TokenFlags.BLOCK_START | TokenFlags.CONTAINER_START | TokenFlags.LINE_START;
					lastToken.flags |= TokenFlags.BLOCK_END | TokenFlags.CONTAINER_END | TokenFlags.LINE_END;
				}
			}

			if (isBlockElement) {
				if (tokenCount > 0) {
					currentBlock!.tokenCount = tokenEndIndex - currentBlock!.startTokenIndex;
					tokens[tokens.length - 1].flags |= TokenFlags.BLOCK_END | TokenFlags.LINE_END;
				}
				currentBlock = blockStack.pop() || null;
			}

			if (isTextFlowContainer) {
				if (tokenCount > 0) {
					currentContainer.tokenCount = tokenEndIndex - currentContainer.startTokenIndex;
					tokens[tokens.length - 1].flags |= TokenFlags.CONTAINER_END | TokenFlags.BLOCK_END | TokenFlags.LINE_END;
					containers.set(node as HTMLElement, currentContainer);
				}
				currentContainer = containerStack.pop()!;
			}
		}

		yield* traverse(root);

		tokens.length = tokenIndex;
		for (let i = 1; i < tokens.length; i++) {
			if (tokens[i].flags & TokenFlags.LINE_START) {
				tokens[i - 1].flags |= TokenFlags.LINE_END;
			}
		}

		return { tokens, containers };
	}
}
